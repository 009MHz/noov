# Selenium Python Test Automation Framework

A comprehensive Selenium-based test automation framework for testing the Noovoleum website using Python, pytest, and Allure reporting.

## ğŸš€ Features

- **Object-Oriented Design**: Page Object Model (POM) implementation
- **Cross-Platform**: Runs on local machines and GitHub Actions
- **Flexible Execution**: Supports both headless and headed browser modes
- **Rich Reporting**: Allure reports with screenshots and detailed logs
- **CI/CD Integration**: Automated testing via GitHub Actions
- **Parallel Execution**: Support for running tests in parallel
- **Test Categories**: Smoke, regression, and critical test markers
- **Retry Mechanism**: Automatic retry for flaky tests

## ğŸ“‹ Prerequisites

- Python 3.9+ 
- Chrome browser
- Git

## ğŸ› ï¸ Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ—ï¸ Project Structure

```
root/
â”œâ”€ README.md
â”œâ”€ pyproject.toml                # or requirements/*.txt per package
â”œâ”€ pytest.ini                    # markers, addopts, allure dir
â”œâ”€ .env.example                  # shared env keys (never commit real secrets)
â”œâ”€ config/
â”‚  â”œâ”€ base.yaml                  # default settings
â”‚  â”œâ”€ dev.yaml                   # env overrides
â”‚  â”œâ”€ staging.yaml
â”‚  â”œâ”€ prod.yaml
â”‚  â””â”€ devices.yaml               # mobile & emulation profiles
â”œâ”€ libs/                         # shared libs reused by all packs
â”‚  â”œâ”€ config_loader.py
â”‚  â”œâ”€ logger.py
â”‚  â”œâ”€ data_factory.py
â”‚  â”œâ”€ allure_utils.py
â”‚  â””â”€ waiters.py
â”œâ”€ common/                       # domain-agnostic abstractions
â”‚  â”œâ”€ pages/                     # base classes
â”‚  â”‚  â”œâ”€ base_page.py
â”‚  â”‚  â”œâ”€ base_mobile_screen.py
â”‚  â”‚  â””â”€ base_api_client.py
â”‚  â””â”€ fixtures/                  # cross-cutting pytest fixtures
â”‚     â”œâ”€ auth_context.py         # reusable login/session (storageState)
â”‚     â”œâ”€ playwright_fixtures.py  # browser/page/context
â”‚     â”œâ”€ appium_fixtures.py      # android/ios drivers
â”‚     â”œâ”€ api_fixtures.py         # request_context
â”‚     â””â”€ env_fixtures.py         # config per run
â”œâ”€ web/                          # desktop & mobile web (Playwright)
â”‚  â”œâ”€ pages/                     # POM pages
â”‚  â”‚  â””â”€ login_page.py
â”‚  â”œâ”€ tests/
â”‚  â”‚  â”œâ”€ smoke/
â”‚  â”‚  â””â”€ regression/
â”‚  â””â”€ elements/                  # locator maps if you separate
â”œâ”€ api/                          # API tests (Playwright request)
â”‚  â”œâ”€ clients/
â”‚  â”‚  â””â”€ auth_client.py
â”‚  â””â”€ tests/
â”œâ”€ mobile/                       # Appium Python (Android/iOS)
â”‚  â”œâ”€ screens/
â”‚  â”‚  â””â”€ login_screen.py
â”‚  â””â”€ tests/
â”œâ”€ perf/                         # Locust load tests
â”‚  â”œâ”€ locustfile.py
â”‚  â””â”€ scenarios/
â”œâ”€ reports/
â”‚  â”œâ”€ allure-results/            # raw results (CI artifact)
â”‚  â””â”€ allure-report/             # generated site (GH Pages)
â””â”€ .github/
   â””â”€ workflows/
      â”œâ”€ ui_api.yml              # web & api
      â”œâ”€ mobile_android.yml
      â”œâ”€ mobile_ios.yml
      â””â”€ publish_allure.yml      # merge + publish to Pages
```

## ğŸ¯ Usage

### Local Execution

**Run all tests:**
```bash
pytest tests/
```

**Run specific test categories:**
```bash
# Smoke tests
pytest tests/ -m smoke

# Regression tests  
pytest tests/ -m regression

# Critical tests
pytest tests/ -m critical
```

**Run in headless mode:**
```bash
pytest tests/ --headless
```

**Run with custom browser:**
```bash
pytest tests/ --browser=chrome
```

**Run with custom base URL:**
```bash
pytest tests/ --base-url=https://noovoleum.com/id/
```

**Parallel execution:**
```bash
pytest tests/ -n auto  # Auto-detect CPU cores
pytest tests/ -n 4     # Use 4 parallel workers
```

### Environment Variables

Set these environment variables to customize test execution:

```bash
export BASE_URL="https://noovoleum.com/id/"
export BROWSER="chrome"
export HEADLESS="false"
export IMPLICIT_WAIT="10"
export EXPLICIT_WAIT="10"
export WINDOW_WIDTH="1920"
export WINDOW_HEIGHT="1080"
```

## ğŸ“Š Reporting

### Allure Reports

**Generate and view Allure reports:**
```bash
# After running tests
allure serve allure-results

# Or generate static report
allure generate allure-results --clean -o allure-report
allure open allure-report
```

### HTML Reports

HTML reports are automatically generated in the `reports/` directory after test execution.

## ğŸ”„ CI/CD Pipeline

The framework includes a comprehensive GitHub Actions workflow that:

- Runs tests on multiple Python versions (3.9, 3.10, 3.11)
- Executes different test suites based on triggers:
  - **Pull Request**: Smoke tests
  - **Push to main**: Critical tests
  - **Scheduled**: Regression tests
  - **Manual trigger**: Configurable test suite
- Generates and deploys Allure reports to GitHub Pages
- Uploads artifacts (reports, screenshots, logs)
- Sends notifications on test results

### Workflow Triggers

```yaml
# Automatic triggers
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC

# Manual trigger with options
workflow_dispatch:
  inputs:
    test_suite: [all, smoke, regression, critical]
    headless: boolean
```

## ğŸ·ï¸ Test Markers

Use pytest markers to categorize and run specific tests:

- `@pytest.mark.smoke`: Quick validation tests
- `@pytest.mark.regression`: Comprehensive functionality tests  
- `@pytest.mark.critical`: Essential functionality tests
- `@pytest.mark.slow`: Long-running tests

## ğŸ”§ Configuration

### pytest.ini
Contains pytest configuration including:
- Test discovery patterns
- Report generation settings
- Allure integration
- Custom markers

### utils/config.py
Centralized configuration management:
- Browser settings
- URL configuration  
- Timeouts and waits
- Chrome options
- Environment detection

## ğŸ“ Writing Tests

### Example Test Structure

```python
@allure.epic("Website")
@allure.feature("Home Page")
@allure.story("Page Loading")
@pytest.mark.smoke
def test_home_page_loads(home_page):
    with allure.step("Navigate to home page"):
        home_page.open()
    
    with allure.step("Verify page loads"):
        assert home_page.is_page_loaded()
```

### Page Object Example

```python
class HomePage(BasePage):
    LOGO = (By.CSS_SELECTOR, ".logo")
    
    def open(self):
        self.navigate_to(self.page_url)
        return self
    
    def is_logo_displayed(self):
        return self.is_displayed(self.LOGO)
```

## ğŸ› Debugging

### Screenshots
Screenshots are automatically captured:
- On test failures
- At specific test steps
- For debugging purposes

### Logs
Detailed logging is available:
- Console output
- File logging (`test_automation.log`)
- Allure step logging

### Debug Mode
Run tests with verbose output:
```bash
pytest tests/ -v -s --tb=long
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ“ Support

For issues and questions:
- Create an issue in the repository
- Check existing documentation
- Review test logs and reports

## ğŸ”„ Updates and Maintenance

- Regularly update dependencies
- Monitor test execution in CI/CD
- Review and update page objects as the website changes  
- Maintain test data and configuration
- Update browser drivers as needed (handled automatically by webdriver-manager)

---

**Happy Testing! ğŸ§ª**